{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pycocotools numpy>=1.21.2 opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Custom Dataset/Pretrained Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the head first\n",
    "!python train.py -c 0 -p taco_waste --head_only True --lr 5e-3 --batch_size 32 --load_weights weights/efficientdet-d0.pth  --num_epochs 10 --save_interval 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then train the entire network\n",
    "!python train.py -c 0 -p taco_waste --head_only False --lr 1e-3 --batch_size 16 --load_weights last  --num_epochs 16 --save_interval 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest weight file\n",
    "%cd logs/taco_waste\n",
    "weight_file = !ls -Art | grep efficientdet\n",
    "%cd ../..\n",
    "\n",
    "#uncomment the next line to specify a weight file\n",
    "#weight_file[-1] = 'efficientdet-d0_49_1400.pth'\n",
    "\n",
    "!python coco_eval.py -c 0 -p taco_waste -w \"logs/taco_waste/{weight_file[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "\n",
    "compound_coef = 0\n",
    "force_input_size = None  # set None to use default size\n",
    "img_path = 'datasets/taco/images/batch_1/000000.jpg'  # Update this path to a sample image from your TACO dataset\n",
    "\n",
    "threshold = 0.2\n",
    "iou_threshold = 0.2\n",
    "\n",
    "use_cuda = True\n",
    "use_float16 = False\n",
    "cudnn.fastest = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Update this list with the categories in your TACO dataset\n",
    "obj_list = ['Plastic bag & wrapper', 'Bottle', 'Can', 'Cup', 'Other plastic', 'Paper', 'Lid', 'Straw', 'Other']\n",
    "\n",
    "# tf bilinear interpolation is different from any other's, just make do\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
    "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
    "\n",
    "if use_cuda:\n",
    "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "else:\n",
    "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
    "\n",
    "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "                             ratios=[(0.7, 1.4), (1.0, 1.0), (1.5, 0.7)],\n",
    "                             scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "model.load_state_dict(torch.load('logs/taco_waste/'+weight_file[-1]))\n",
    "model.requires_grad_(False)\n",
    "model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "if use_float16:\n",
    "    model = model.half()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features, regression, classification, anchors = model(x)\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    out = postprocess(x,\n",
    "                      anchors, regression, classification,\n",
    "                      regressBoxes, clipBoxes,\n",
    "                      threshold, iou_threshold)\n",
    "\n",
    "out = invert_affine(framed_metas, out)\n",
    "\n",
    "for i in range(len(ori_imgs)):\n",
    "    if len(out[i]['rois']) == 0:\n",
    "        continue\n",
    "    ori_imgs[i] = ori_imgs[i].copy()\n",
    "    for j in range(len(out[i]['rois'])):\n",
    "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
    "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "        obj = obj_list[out[i]['class_ids'][j]]\n",
    "        score = float(out[i]['scores'][j])\n",
    "\n",
    "        cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
    "                    (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (255, 255, 0), 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(ori_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
