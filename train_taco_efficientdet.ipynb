{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pycocotools numpy==1.16.0 opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if \"projects\" not in os.getcwd():\n",
    "    os.chdir('Yet-Another-EfficientDet-Pytorch')\n",
    "    sys.path.append('.')\n",
    "else:\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat projects/taco.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -c 0 -p taco --head_only True --lr 1e-3 --batch_size 16 --load_weights weights/efficientdet-d0.pth --num_epochs 50 --save_interval 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -c 0 -p taco --head_only False --lr 1e-4 --batch_size 8 --load_weights last --num_epochs 100 --save_interval 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd logs/taco\n",
    "weight_file = !ls -Art | grep efficientdet\n",
    "%cd ../..\n",
    "print(f\"Latest weight file: {weight_file[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco_eval import evaluate_coco\n",
    "\n",
    "# Adjust these paths according to your setup\n",
    "img_path = 'datasets/taco/val/'\n",
    "set_name = 'val'\n",
    "weights_path = f'logs/taco/{weight_file[-1]}'\n",
    "\n",
    "# Load your TACO dataset and model\n",
    "# This part depends on how you've structured your dataset and model loading\n",
    "# You may need to adapt it based on the COCO dataset structure\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_coco(img_path, set_name, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "\n",
    "# Load your TACO object list\n",
    "obj_list = ['Plastic bag & wrapper', 'Bottle', 'Bottle cap', 'Can', 'Other plastic', 'Other metal', 'Carton', 'Cup', 'Lid', 'Paper', 'Plastic container', 'Plastic utensils', 'Pop tab', 'Straw', 'Styrofoam piece', 'Unlabeled litter']\n",
    "\n",
    "# Load model and weights\n",
    "compound_coef = 0\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list))\n",
    "model.load_state_dict(torch.load(f'logs/taco/{weight_file[-1]}'))\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess an image\n",
    "img_path = 'datasets/taco/val/your_test_image.jpg'  # replace with an actual image from your dataset\n",
    "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=512)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    x = torch.from_numpy(framed_imgs[0]).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    features, regression, classification, anchors = model(x)\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    out = postprocess(x, anchors, regression, classification, regressBoxes, clipBoxes, 0.2, 0.2)\n",
    "    out = invert_affine(framed_metas, out)\n",
    "\n",
    "# Visualize results\n",
    "for i in range(len(ori_imgs)):\n",
    "    if len(out[i]['rois']) == 0:\n",
    "        continue\n",
    "    for j in range(len(out[i]['rois'])):\n",
    "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
    "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "        obj = obj_list[out[i]['class_ids'][j]]\n",
    "        score = float(out[i]['scores'][j])\n",
    "        cv2.putText(ori_imgs[i], f'{obj}, {score:.3f}', (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(ori_imgs[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
